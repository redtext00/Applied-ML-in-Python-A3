{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7ebad64",
   "metadata": {},
   "source": [
    "# Assignment 3 - Evaluation\n",
    "\n",
    "In this assignment you will train several models and evaluate how effectively they predict instances of fraud using data based on [this dataset from Kaggle](https://www.kaggle.com/dalpozz/creditcardfraud).\n",
    " \n",
    "Each row in `fraud_data.csv` corresponds to a credit card transaction. Features include confidential variables `V1` through `V28` as well as `Amount` which is the amount of the transaction. \n",
    " \n",
    "The target is stored in the `class` column, where a value of 1 corresponds to an instance of fraud and 0 corresponds to an instance of not fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfbbe6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the dependency here\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14707b92",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Import the data from `fraud_data.csv`. What percentage of the observations in the dataset are instances of fraud?\n",
    "\n",
    "*This function should return a float between 0 and 1.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f0b5011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016410823768035772"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_one():\n",
    "    \n",
    "    # Your code here\n",
    "    df = pd.read_csv('readonly/fraud_data.csv')\n",
    "    \n",
    "    # class = 1 - fraud\n",
    "    # class = 0 - no fraud\n",
    "    \n",
    "    adj = df['Class']\n",
    "    top = df[df.Class == 1]\n",
    "    topnum = len(top)\n",
    "    topnum\n",
    "    bnum = len(df)\n",
    "    bnum\n",
    "    answer = topnum/bnum\n",
    "    answer\n",
    "    \n",
    "    \n",
    "    return answer # Return your answer\n",
    "answer_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2179971c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d20f4884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use X_train, X_test, y_train, y_test for all of the following questions\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('readonly/fraud_data.csv')\n",
    "\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02c04e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.176563</td>\n",
       "      <td>0.323798</td>\n",
       "      <td>0.536927</td>\n",
       "      <td>1.047002</td>\n",
       "      <td>-0.368652</td>\n",
       "      <td>-0.728586</td>\n",
       "      <td>0.084678</td>\n",
       "      <td>-0.069246</td>\n",
       "      <td>-0.266389</td>\n",
       "      <td>0.155315</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.137258</td>\n",
       "      <td>-0.109627</td>\n",
       "      <td>-0.341365</td>\n",
       "      <td>0.057845</td>\n",
       "      <td>0.499180</td>\n",
       "      <td>0.415211</td>\n",
       "      <td>-0.581949</td>\n",
       "      <td>0.015472</td>\n",
       "      <td>0.018065</td>\n",
       "      <td>4.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.681109</td>\n",
       "      <td>-3.934776</td>\n",
       "      <td>-3.801827</td>\n",
       "      <td>-1.147468</td>\n",
       "      <td>-0.735540</td>\n",
       "      <td>-0.501097</td>\n",
       "      <td>1.038865</td>\n",
       "      <td>-0.626979</td>\n",
       "      <td>-2.274423</td>\n",
       "      <td>1.527782</td>\n",
       "      <td>...</td>\n",
       "      <td>1.341809</td>\n",
       "      <td>0.652202</td>\n",
       "      <td>0.272684</td>\n",
       "      <td>-0.982151</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>0.360251</td>\n",
       "      <td>0.195321</td>\n",
       "      <td>-0.256273</td>\n",
       "      <td>0.056501</td>\n",
       "      <td>912.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.140729</td>\n",
       "      <td>0.453484</td>\n",
       "      <td>0.247010</td>\n",
       "      <td>2.383132</td>\n",
       "      <td>0.343287</td>\n",
       "      <td>0.432804</td>\n",
       "      <td>0.093380</td>\n",
       "      <td>0.173310</td>\n",
       "      <td>-0.808999</td>\n",
       "      <td>0.775436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232185</td>\n",
       "      <td>-0.003802</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>-0.121177</td>\n",
       "      <td>-0.304215</td>\n",
       "      <td>0.645893</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>-0.012115</td>\n",
       "      <td>-0.005945</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.107073</td>\n",
       "      <td>-3.298902</td>\n",
       "      <td>-0.184092</td>\n",
       "      <td>-1.795744</td>\n",
       "      <td>2.137564</td>\n",
       "      <td>-1.684992</td>\n",
       "      <td>-2.015606</td>\n",
       "      <td>-0.007181</td>\n",
       "      <td>-0.165760</td>\n",
       "      <td>0.869659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348269</td>\n",
       "      <td>0.130648</td>\n",
       "      <td>0.329445</td>\n",
       "      <td>0.927656</td>\n",
       "      <td>-0.049560</td>\n",
       "      <td>-1.892866</td>\n",
       "      <td>-0.575431</td>\n",
       "      <td>0.266573</td>\n",
       "      <td>0.414184</td>\n",
       "      <td>62.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.314818</td>\n",
       "      <td>0.866839</td>\n",
       "      <td>-0.124577</td>\n",
       "      <td>-0.627638</td>\n",
       "      <td>2.651762</td>\n",
       "      <td>3.428128</td>\n",
       "      <td>0.194637</td>\n",
       "      <td>0.670674</td>\n",
       "      <td>-0.442658</td>\n",
       "      <td>0.133499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402329</td>\n",
       "      <td>-0.312774</td>\n",
       "      <td>-0.799494</td>\n",
       "      <td>-0.064488</td>\n",
       "      <td>0.953062</td>\n",
       "      <td>-0.429550</td>\n",
       "      <td>0.158225</td>\n",
       "      <td>0.076943</td>\n",
       "      <td>-0.015051</td>\n",
       "      <td>2.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21688</th>\n",
       "      <td>-3.959670</td>\n",
       "      <td>3.297819</td>\n",
       "      <td>-1.079436</td>\n",
       "      <td>-2.290106</td>\n",
       "      <td>-1.405133</td>\n",
       "      <td>2.452586</td>\n",
       "      <td>-4.649235</td>\n",
       "      <td>-12.365464</td>\n",
       "      <td>0.409493</td>\n",
       "      <td>1.251992</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.572780</td>\n",
       "      <td>12.617463</td>\n",
       "      <td>-2.969195</td>\n",
       "      <td>1.755050</td>\n",
       "      <td>0.433324</td>\n",
       "      <td>-0.010827</td>\n",
       "      <td>-0.126613</td>\n",
       "      <td>0.200111</td>\n",
       "      <td>-0.160542</td>\n",
       "      <td>29.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21689</th>\n",
       "      <td>-1.066503</td>\n",
       "      <td>0.539240</td>\n",
       "      <td>0.735343</td>\n",
       "      <td>-0.506800</td>\n",
       "      <td>0.843980</td>\n",
       "      <td>-1.047877</td>\n",
       "      <td>1.141302</td>\n",
       "      <td>-0.127448</td>\n",
       "      <td>-0.119221</td>\n",
       "      <td>-1.870265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232487</td>\n",
       "      <td>-0.162535</td>\n",
       "      <td>-0.576352</td>\n",
       "      <td>-0.184969</td>\n",
       "      <td>-0.136154</td>\n",
       "      <td>0.760012</td>\n",
       "      <td>0.048105</td>\n",
       "      <td>-0.017475</td>\n",
       "      <td>0.092365</td>\n",
       "      <td>85.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21690</th>\n",
       "      <td>-2.175162</td>\n",
       "      <td>-0.441681</td>\n",
       "      <td>1.883137</td>\n",
       "      <td>-0.267440</td>\n",
       "      <td>1.056972</td>\n",
       "      <td>0.136404</td>\n",
       "      <td>0.113595</td>\n",
       "      <td>-0.055983</td>\n",
       "      <td>0.765616</td>\n",
       "      <td>-0.087568</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.217800</td>\n",
       "      <td>-0.201561</td>\n",
       "      <td>0.397761</td>\n",
       "      <td>-0.855500</td>\n",
       "      <td>-0.627900</td>\n",
       "      <td>0.590977</td>\n",
       "      <td>0.515065</td>\n",
       "      <td>0.433089</td>\n",
       "      <td>-0.150291</td>\n",
       "      <td>131.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21691</th>\n",
       "      <td>0.031406</td>\n",
       "      <td>0.694817</td>\n",
       "      <td>0.083233</td>\n",
       "      <td>-0.797912</td>\n",
       "      <td>0.564318</td>\n",
       "      <td>-0.560787</td>\n",
       "      <td>0.805901</td>\n",
       "      <td>0.051453</td>\n",
       "      <td>-0.053817</td>\n",
       "      <td>-0.200190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.101536</td>\n",
       "      <td>-0.255891</td>\n",
       "      <td>-0.664635</td>\n",
       "      <td>0.018844</td>\n",
       "      <td>-0.539177</td>\n",
       "      <td>-0.504019</td>\n",
       "      <td>0.155133</td>\n",
       "      <td>0.232846</td>\n",
       "      <td>0.079420</td>\n",
       "      <td>4.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21692</th>\n",
       "      <td>-0.312369</td>\n",
       "      <td>0.944738</td>\n",
       "      <td>1.430605</td>\n",
       "      <td>0.627951</td>\n",
       "      <td>0.317725</td>\n",
       "      <td>-0.180406</td>\n",
       "      <td>0.793108</td>\n",
       "      <td>-0.104993</td>\n",
       "      <td>-0.493956</td>\n",
       "      <td>0.344477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218321</td>\n",
       "      <td>0.118417</td>\n",
       "      <td>0.609081</td>\n",
       "      <td>-0.270644</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>-0.114185</td>\n",
       "      <td>-0.287989</td>\n",
       "      <td>0.232375</td>\n",
       "      <td>-0.023563</td>\n",
       "      <td>14.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21693 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0      1.176563  0.323798  0.536927  1.047002 -0.368652 -0.728586  0.084678   \n",
       "1      0.681109 -3.934776 -3.801827 -1.147468 -0.735540 -0.501097  1.038865   \n",
       "2      1.140729  0.453484  0.247010  2.383132  0.343287  0.432804  0.093380   \n",
       "3     -1.107073 -3.298902 -0.184092 -1.795744  2.137564 -1.684992 -2.015606   \n",
       "4     -0.314818  0.866839 -0.124577 -0.627638  2.651762  3.428128  0.194637   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "21688 -3.959670  3.297819 -1.079436 -2.290106 -1.405133  2.452586 -4.649235   \n",
       "21689 -1.066503  0.539240  0.735343 -0.506800  0.843980 -1.047877  1.141302   \n",
       "21690 -2.175162 -0.441681  1.883137 -0.267440  1.056972  0.136404  0.113595   \n",
       "21691  0.031406  0.694817  0.083233 -0.797912  0.564318 -0.560787  0.805901   \n",
       "21692 -0.312369  0.944738  1.430605  0.627951  0.317725 -0.180406  0.793108   \n",
       "\n",
       "              V8        V9       V10  ...       V20        V21       V22  \\\n",
       "0      -0.069246 -0.266389  0.155315  ... -0.137258  -0.109627 -0.341365   \n",
       "1      -0.626979 -2.274423  1.527782  ...  1.341809   0.652202  0.272684   \n",
       "2       0.173310 -0.808999  0.775436  ... -0.232185  -0.003802  0.058556   \n",
       "3      -0.007181 -0.165760  0.869659  ...  0.348269   0.130648  0.329445   \n",
       "4       0.670674 -0.442658  0.133499  ...  0.402329  -0.312774 -0.799494   \n",
       "...          ...       ...       ...  ...       ...        ...       ...   \n",
       "21688 -12.365464  0.409493  1.251992  ... -2.572780  12.617463 -2.969195   \n",
       "21689  -0.127448 -0.119221 -1.870265  ...  0.232487  -0.162535 -0.576352   \n",
       "21690  -0.055983  0.765616 -0.087568  ... -0.217800  -0.201561  0.397761   \n",
       "21691   0.051453 -0.053817 -0.200190  ... -0.101536  -0.255891 -0.664635   \n",
       "21692  -0.104993 -0.493956  0.344477  ...  0.218321   0.118417  0.609081   \n",
       "\n",
       "            V23       V24       V25       V26       V27       V28  Amount  \n",
       "0      0.057845  0.499180  0.415211 -0.581949  0.015472  0.018065    4.67  \n",
       "1     -0.982151  0.165900  0.360251  0.195321 -0.256273  0.056501  912.00  \n",
       "2     -0.121177 -0.304215  0.645893  0.122600 -0.012115 -0.005945    1.00  \n",
       "3      0.927656 -0.049560 -1.892866 -0.575431  0.266573  0.414184   62.10  \n",
       "4     -0.064488  0.953062 -0.429550  0.158225  0.076943 -0.015051    2.67  \n",
       "...         ...       ...       ...       ...       ...       ...     ...  \n",
       "21688  1.755050  0.433324 -0.010827 -0.126613  0.200111 -0.160542   29.95  \n",
       "21689 -0.184969 -0.136154  0.760012  0.048105 -0.017475  0.092365   85.66  \n",
       "21690 -0.855500 -0.627900  0.590977  0.515065  0.433089 -0.150291  131.10  \n",
       "21691  0.018844 -0.539177 -0.504019  0.155133  0.232846  0.079420    4.49  \n",
       "21692 -0.270644  0.004333 -0.114185 -0.287989  0.232375 -0.023563   14.90  \n",
       "\n",
       "[21693 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9874a49d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "21688    0\n",
       "21689    0\n",
       "21690    0\n",
       "21691    0\n",
       "21692    0\n",
       "Name: Class, Length: 21693, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99da8323",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Using `X_train`, `X_test`, `y_train`, and `y_test` (as defined above), train a dummy classifier that classifies everything as the majority class of the training data. What is the accuracy of this classifier? What is the recall?\n",
    "\n",
    "*This function should a return a tuple with two floats, i.e. `(accuracy score, recall score)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1948e13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9852507374631269, 0.0)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_two():\n",
    "    from sklearn.dummy import DummyClassifier\n",
    "    from sklearn.metrics import recall_score\n",
    "    \n",
    "    # Your code here\n",
    "    \n",
    "    dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "    dummy_clf.fit(X, y)\n",
    "    acc = dummy_clf.score(X_test, y_test)\n",
    "    y_pred = dummy_clf.predict(X_test)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    tup = (acc, rec)\n",
    "    \n",
    "    return tup # Return your answer\n",
    "answer_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed9eb0d",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Using X_train, X_test, y_train, y_test (as defined above), train a SVC classifer using the default parameters. What is the accuracy, recall, and precision of this classifier?\n",
    "\n",
    "*This function should a return a tuple with three floats, i.e. `(accuracy score, recall score, precision score)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e3fc50ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9900442477876106, 0.35, 0.9333333333333333)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_three():\n",
    "    from sklearn.metrics import recall_score, precision_score, accuracy_score\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "    # Your code here\n",
    "    \n",
    "    #import\n",
    "    from sklearn.pipeline import make_pipeline\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    # clf\n",
    "    clf = SVC().fit(X_train, y_train)\n",
    "    \n",
    "    # predict \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # accuracy score\n",
    "    acc = clf.score(X_test, y_test)\n",
    "    \n",
    "    # recall score\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    \n",
    "    # precision score\n",
    "    pre = precision_score(y_test, y_pred)\n",
    "    \n",
    "    return (acc, rec, pre) # Return your answer\n",
    "answer_three()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015ca7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "229fe0f5",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Using the SVC classifier with parameters `{'C': 1e9, 'gamma': 1e-07}`, what is the confusion matrix when using a threshold of -220 on the decision function. Use X_test and y_test.\n",
    "\n",
    "*This function should return a confusion matrix, a 2x2 numpy array with 4 integers.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "153e7635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5320,   24],\n",
       "       [  14,   66]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_four():\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "    # Your code here\n",
    "    svc = SVC(C = 1e9, gamma = 1e-07, probability=True).fit(X_train, y_train)\n",
    "    threshold = -220\n",
    "    \n",
    "    df = svc.decision_function(X_test)\n",
    "\n",
    "    desired_predict =[]\n",
    "\n",
    "    for i in df:\n",
    "        if i<threshold:\n",
    "            desired_predict.append(0)\n",
    "        else:\n",
    "            desired_predict.append(1)\n",
    "    \n",
    "    cm = confusion_matrix( y_test , desired_predict )\n",
    "    \n",
    "    return cm# Return your answer\n",
    "answer_four()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f40768",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Train a logisitic regression classifier with default parameters using X_train and y_train.\n",
    "\n",
    "For the logisitic regression classifier, create a precision recall curve and a roc curve using y_test and the probability estimates for X_test (probability it is fraud).\n",
    "\n",
    "Looking at the precision recall curve, what is the recall when the precision is `0.75`?\n",
    "\n",
    "Looking at the roc curve, what is the true positive rate when the false positive rate is `0.16`?\n",
    "\n",
    "*This function should return a tuple with two floats, i.e. `(recall, true positive rate)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3828411b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8, 0.9)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def answer_five(#argument here):\n",
    "        \n",
    "    # Your code here\n",
    "    \n",
    "    # clf\n",
    "    clf = LogisticRegression().fit(X_train, y_train)\n",
    "    \n",
    "    # precision recall curve with precision 0.75\n",
    "    display = PrecisionRecallDisplay.from_estimator(\n",
    "    clf, X_test, y_test, name=\"LinearSVC\"\n",
    "    )\n",
    "    \n",
    "    ans1 = 0.8\n",
    "    \n",
    "    # roc curve; true positive rate with false positive rate of 0.16\n",
    "    ans2 = 0.9\n",
    "    \n",
    "    \n",
    "    return (ans1, ans2) # Return your answer\n",
    "answer_five()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c6b92390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve,PrecisionRecallDisplay\n",
    "from sklearn import metrics\n",
    "   \n",
    "def funct1():\n",
    "    \n",
    "    #clf : WRITE DOWN WHAT CLF MEANS\n",
    "    clf = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "    # precision recall curve with precision 0.75\n",
    "    display = PrecisionRecallDisplay.from_estimator(\n",
    "    clf, X_test, y_test, name=\"LinearSVC\"\n",
    "    )\n",
    "\n",
    "    \n",
    "#funct1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "89f881a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funct2():\n",
    "    # roc curve; true positive rate with false positive rate of 0.16\n",
    "    #from sklearn.linear_model import LogisticRegression\n",
    "    #from sklearn.metrics import (precision_recall_curve,\n",
    "    #                             PrecisionRecallDisplay)\n",
    "    #from sklearn import metrics\n",
    "    clf = LogisticRegression().fit(X_train, y_train)\n",
    "    metrics.plot_roc_curve(clf, X_test, y_test) \n",
    "#funct2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742669d5",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Perform a grid search over the parameters listed below for a Logisitic Regression classifier, using recall for scoring and the default 3-fold cross validation.\n",
    "\n",
    "`'penalty': ['l1', 'l2']`\n",
    "\n",
    "`'C':[0.01, 0.1, 1, 10, 100]`\n",
    "\n",
    "From `.cv_results_`, create an array of the mean test scores of each parameter combination. i.e.\n",
    "\n",
    "|      \t| `l1` \t| `l2` \t|\n",
    "|:----:\t|----\t|----\t|\n",
    "| **`0.01`** \t|    ?\t|   ? \t|\n",
    "| **`0.1`**  \t|    ?\t|   ? \t|\n",
    "| **`1`**    \t|    ?\t|   ? \t|\n",
    "| **`10`**   \t|    ?\t|   ? \t|\n",
    "| **`100`**   \t|    ?\t|   ? \t|\n",
    "\n",
    "<br>\n",
    "\n",
    "*This function should return a 5 by 2 numpy array with 10 floats.* \n",
    "\n",
    "*Note: do not return a DataFrame, just the values denoted by '?' above in a numpy array. You might need to reshape your raw result to meet the format we are looking for.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8671675f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "25 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.80064935        nan 0.80785714        nan 0.80428571\n",
      "        nan 0.79694805        nan 0.81512987]\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[       nan, 0.80064935],\n",
       "       [       nan, 0.80785714],\n",
       "       [       nan, 0.80428571],\n",
       "       [       nan, 0.79694805],\n",
       "       [       nan, 0.81512987]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_six(grid):    \n",
    "    '''\n",
    "    **move this outside of a function**\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    '''\n",
    "    # Your code here\n",
    "    #grid  = {'penalty': ['l1', 'l2'], 'C':[0.01, 0.1, 1, 10, 100]}\n",
    "    clf = LogisticRegression()\n",
    "    log=GridSearchCV(clf, param_grid = grid, scoring = 'recall')\n",
    "    log.fit(X_train, y_train)\n",
    "    \n",
    "    return np.array(log.cv_results_['mean_test_score'].reshape(5,2)) # Return your answer\n",
    "\n",
    "grid_dict  = {'penalty': ['l1', 'l2'], 'C':[0.01, 0.1, 1, 10, 100]}\n",
    "mean_test_array = answer_six(grid_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fbc8892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following function to help visualize results from the grid search\n",
    "def GridSearch_Heatmap(scores):\n",
    "    #%matplotlib notebook\n",
    "    #import seaborn as sns\n",
    "    #import matplotlib.pyplot as plt\n",
    "    #plt.figure()\n",
    "    #sns.heatmap(scores.reshape(5,2), xticklabels=['l1','l2'], yticklabels=[0.01, 0.1, 1, 10, 100])\n",
    "    #plt.yticks(rotation=0);\n",
    "\n",
    "#GridSearch_Heatmap(answer_six())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ea1d30a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "25 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.80064935        nan 0.80785714        nan 0.80428571\n",
      "        nan 0.79694805        nan 0.81512987]\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([       nan, 0.80064935,        nan, 0.80785714,        nan,\n",
       "       0.80428571,        nan, 0.79694805,        nan, 0.81512987])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Your code here\n",
    "grid  = {'penalty': ['l1', 'l2'], 'C':[0.01, 0.1, 1, 10, 100]}\n",
    "clf = LogisticRegression()\n",
    "log=GridSearchCV(clf, param_grid = grid, scoring = 'recall')\n",
    "log.fit(X_train, y_train)\n",
    "log.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9320312c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100], &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;]},\n",
       "             scoring=&#x27;recall&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100], &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;]},\n",
       "             scoring=&#x27;recall&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2']},\n",
       "             scoring='recall')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c429f84b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
